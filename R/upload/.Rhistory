}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "darkblue",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('darkblue',"darkblue","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
exp_data <- matrix(NaN,nrow = (nReps*length(p)),ncol = 4)
for(i in 1:length(p)){
for(j in 1:nReps){
long_ticker = (i-1)*nReps+j
exp_data[long_ticker,1] <- p[long_ticker]
exp_data[long_ticker,2] <- y[long_ticker]
if(exp_data[long_ticker,2]==2){
exp_data[long_ticker,2]<- 0
}
}
}
exp_overlay <- matrix(NaN,nrow = 10,ncol = 4)
exp_overlay[,1] <- seq(.035,.935,by = .1)
bin_size_exp = rep(NaN,10)
for(i in 1:nrow(exp_overlay)){
tol = .0001
lo = (i*.1)-.1
hi = i * .1
templo <- exp_data
templo[,1] <- templo[,1]+tol
temp_bin1 <- exp_data[which(templo[,1]>lo),1:2]
temphi <- temp_bin1
temphi[,1] <- temphi[,1]+tol
if(i<10){
temp_bin2 <- temp_bin1[which(temphi[,1]<hi),2]
}
else{temp_bin2 <- temp_bin1[,2]}
bin_size_exp[i] = length(temp_bin2)
exp_overlay[i,2] <- mean(temp_bin2)
nSamples = 10
nIterations = 1000
if(i==1){nSamples = 2}
bootRange <- BootstrapMean95(temp_bin2,nSamples,nIterations)
exp_overlay[i,3:4] <- bootRange
}
# Calculate inexperienced interpretation for comparison -------------------
nParticipants <- max(SONAData$Participant)
nResponses_SONA <- nParticipants * nReps
SONA_vector <- c(SONAData$EarlyResponse[which(SONAData$SpeakerEarly==1)],
SONAData$LateResponse[which(SONAData$SpeakerLate==1)])
SONA_descriptives <- matrix(NaN,nrow = 3,ncol = 1)
SONA_descriptives[1,1] <- mean(SONA_vector)
nIterations = 1000
nSamples = 100
SONA_descriptives[2:3,1] <- BootstrapMean95(SONA_vector,nSamples,nIterations)
# Alex plot for hierarchical by participant --------------------------------------------------
par(mfrow=c(1,1))
plot_index <- floor(runif(4000, min=1, max=12001))
q = seq(0,1,by = .01)
q_odds <- q/(1-q)
q_logodds <- log(q_odds)
temp_hierarchical <- q
plot(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)),frame.plot = FALSE,
axes = FALSE,xlab = '',ylab = '')
xlabels = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
xat = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
axis(side=1,pos=0,cex.axis = 1.4,lwd = 2,labels = xlabels,at = xat)
axis(side = 2, pos=0,cex.axis = 1.5,lwd = 2)
lines(x = c(0,1),y=c(0,0),lwd =2)
lines(x = c(0,1),y = c(.5,.5),lty = 4)
lines(x = c(.5,.5),y = c(0,1),lty = 4)
for(i in 2:length(alphaGrand_linking)){
temp_hierarchical <- 1/(1 + exp(-betaGrand_linking[plot_index[i]]*(q_logodds-alphaGrand_linking[plot_index[i]])))
lines(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)))
}
# plot_index <- floor(runif(4000, min=1, max=12001))
points(x=exp_overlay[,1],y=exp_overlay[,2],col = "darkblue",pch = 16, cex = 2.2)
for(i in 1:nrow(exp_overlay)){
if(exp_overlay[i,3]-exp_overlay[i,4]!=0){
if(exp_overlay[i,3]==0){
exp_overlay[i,3] <- exp_overlay[i,3]+.005
}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "darkblue",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('black',"black","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
exp_data <- matrix(NaN,nrow = (nReps*length(p)),ncol = 4)
for(i in 1:length(p)){
for(j in 1:nReps){
long_ticker = (i-1)*nReps+j
exp_data[long_ticker,1] <- p[long_ticker]
exp_data[long_ticker,2] <- y[long_ticker]
if(exp_data[long_ticker,2]==2){
exp_data[long_ticker,2]<- 0
}
}
}
exp_overlay <- matrix(NaN,nrow = 10,ncol = 4)
exp_overlay[,1] <- seq(.035,.935,by = .1)
bin_size_exp = rep(NaN,10)
for(i in 1:nrow(exp_overlay)){
tol = .0001
lo = (i*.1)-.1
hi = i * .1
templo <- exp_data
templo[,1] <- templo[,1]+tol
temp_bin1 <- exp_data[which(templo[,1]>lo),1:2]
temphi <- temp_bin1
temphi[,1] <- temphi[,1]+tol
if(i<10){
temp_bin2 <- temp_bin1[which(temphi[,1]<hi),2]
}
else{temp_bin2 <- temp_bin1[,2]}
bin_size_exp[i] = length(temp_bin2)
exp_overlay[i,2] <- mean(temp_bin2)
nSamples = 10
nIterations = 1000
if(i==1){nSamples = 2}
bootRange <- BootstrapMean95(temp_bin2,nSamples,nIterations)
exp_overlay[i,3:4] <- bootRange
}
# Calculate inexperienced interpretation for comparison -------------------
nParticipants <- max(SONAData$Participant)
nResponses_SONA <- nParticipants * nReps
SONA_vector <- c(SONAData$EarlyResponse[which(SONAData$SpeakerEarly==1)],
SONAData$LateResponse[which(SONAData$SpeakerLate==1)])
SONA_descriptives <- matrix(NaN,nrow = 3,ncol = 1)
SONA_descriptives[1,1] <- mean(SONA_vector)
nIterations = 1000
nSamples = 100
SONA_descriptives[2:3,1] <- BootstrapMean95(SONA_vector,nSamples,nIterations)
# Alex plot for hierarchical by participant --------------------------------------------------
par(mfrow=c(1,1))
plot_index <- floor(runif(4000, min=1, max=12001))
q = seq(0,1,by = .01)
q_odds <- q/(1-q)
q_logodds <- log(q_odds)
temp_hierarchical <- q
plot(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)),frame.plot = FALSE,
axes = FALSE,xlab = '',ylab = '')
xlabels = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
xat = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
axis(side=1,pos=0,cex.axis = 1.4,lwd = 2,labels = xlabels,at = xat)
axis(side = 2, pos=0,cex.axis = 1.5,lwd = 2)
lines(x = c(0,1),y=c(0,0),lwd =2)
lines(x = c(0,1),y = c(.5,.5),lty = 4)
lines(x = c(.5,.5),y = c(0,1),lty = 4)
for(i in 2:length(alphaGrand_linking)){
temp_hierarchical <- 1/(1 + exp(-betaGrand_linking[plot_index[i]]*(q_logodds-alphaGrand_linking[plot_index[i]])))
lines(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)))
}
# plot_index <- floor(runif(4000, min=1, max=12001))
points(x=exp_overlay[,1],y=exp_overlay[,2],col = "darkblue",pch = 16, cex = 2.2)
for(i in 1:nrow(exp_overlay)){
if(exp_overlay[i,3]-exp_overlay[i,4]!=0){
if(exp_overlay[i,3]==0){
exp_overlay[i,3] <- exp_overlay[i,3]+.005
}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "darkblue",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('black',"black","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
par(mfrow=c(1,1))
plot_index <- floor(runif(4000, min=1, max=12001))
q = seq(0,1,by = .01)
q_odds <- q/(1-q)
q_logodds <- log(q_odds)
temp_hierarchical <- q
plot(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)),frame.plot = FALSE,
axes = FALSE,xlab = '',ylab = '')
xlabels = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
xat = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
axis(side=1,pos=0,cex.axis = 1.4,lwd = 2,labels = xlabels,at = xat)
axis(side = 2, pos=0,cex.axis = 1.5,lwd = 2)
lines(x = c(0,1),y=c(0,0),lwd =2)
lines(x = c(0,1),y = c(.5,.5),lty = 4)
lines(x = c(.5,.5),y = c(0,1),lty = 4)
for(i in 2:length(alphaGrand_linking)){
temp_hierarchical <- 1/(1 + exp(-betaGrand_linking[plot_index[i]]*(q_logodds-alphaGrand_linking[plot_index[i]])))
lines(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)))
}
# plot_index <- floor(runif(4000, min=1, max=12001))
points(x=exp_overlay[,1],y=exp_overlay[,2],col = "black",pch = 16, cex = 2.2)
for(i in 1:nrow(exp_overlay)){
if(exp_overlay[i,3]-exp_overlay[i,4]!=0){
if(exp_overlay[i,3]==0){
exp_overlay[i,3] <- exp_overlay[i,3]+.005
}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "black",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('black',"black","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
# clears workspace:
rm(list=ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#load(".RData")
library(tidyverse)
library(BayesFactor)
library(corrplot)
library(polspline)
library(R2jags)
source("BootstrapMean95.R")
source("PlotFunc_horizontal.R")
# Load data --------------------------------------------------------
OnlineData <- read_csv("OnlineData.csv",col_names=TRUE)
nExperts = max(OnlineData$Participant)
nItems = 24
SONAData <- read_csv("SONAData.csv",col_names=TRUE)
nNovices = max(SONAData$Participant)
totalNovice = nItems*nNovices
# Prep data for JAGS ------------------------------------------------------
nExp <- nExperts
nReps <- nItems
p <- c(OnlineData$EarlyPrior,OnlineData$LatePrior)
y <- c(OnlineData$EarlyTVJ,OnlineData$LateTVJ)
# Run JAGS model ----------------------------------------------------------
data <- list("nReps","y","p","nExp") # to be passed on to JAGS
# myinits <- list(
#   list("muGrand" = runif(1,0,1), "v" = 3,"prior_v" = 3))
# parameters to be monitored:
parameters <- c("alphaGrand","betaGrand","alpha_sigma","beta_sigma","alphaDelta","betaDelta","alpha","beta")
#Now use jags.parallel to run multiple chains much quicker, adjust chains in n.chains
samples =jags.parallel(data,
#inits=inits.jagsParallel(),
parameters.to.save = parameters,
model.file="hierarchical_aud_LoLComp.txt",n.chains=4,n.thin=1,n.burnin=1000,n.iter=4000)
# End parallel running section
# Now the values for the monitored parameters are in the "samples" object,
# ready for inspection.
samples_linking <- samples
alphaGrand_linking    <- samples_linking$BUGSoutput$sims.list$alphaGrand
betaGrand_linking <- samples_linking$BUGSoutput$sims.list$betaGrand
alphaDelta_linking    <- samples_linking$BUGSoutput$sims.list$alphaDelta
betaDelta_linking <- samples_linking$BUGSoutput$sims.list$betaDelta
alpha_linking    <- samples_linking$BUGSoutput$sims.list$alpha
beta_linking <- samples_linking$BUGSoutput$sims.list$beta
sigmaAlpha_linking <- samples_linking$BUGSoutput$sims.list$alpha_sigma
sigmaBeta_linking <- samples_linking$BUGSoutput$sims.list$beta_sigma
chainlength = nrow(alphaGrand_linking)/4
DIC_linking = samples_linking$BUGSoutput$DIC
# Calculations for inference table (95% CI's) -------------------------------------
lo = 12000*.05
hi = 12000*.95
inference_table <- matrix(NaN, nrow = 8, ncol = 3)
inference_table[1,1] <- mean(alphaGrand_linking)
tempsort <- sort(alphaGrand_linking)
inference_table[1,2] <- tempsort[lo]
inference_table[1,3] <- tempsort[hi]
inference_table[3,1] <- mean(betaGrand_linking)
tempsort <- sort(betaGrand_linking)
inference_table[3,2] <- tempsort[lo]
inference_table[3,3] <- tempsort[hi]
inference_table[5,1] <- mean(sigmaAlpha_linking)
tempsort <- sort(sigmaAlpha_linking)
inference_table[5,2] <- tempsort[lo]
inference_table[5,3] <- tempsort[hi]
inference_table[7,1] <- mean(sigmaBeta_linking)
tempsort <- sort(sigmaBeta_linking)
inference_table[7,2] <- tempsort[lo]
inference_table[7,3] <- tempsort[hi]
mean(sigmaAlpha_linking)
# Set up binned overlay for main plot -------------------------------------
nReps_nov = 12
exp_data <- matrix(NaN,nrow = (nReps*length(p)),ncol = 4)
for(i in 1:length(p)){
for(j in 1:nReps){
long_ticker = (i-1)*nReps_nov+j
exp_data[long_ticker,1] <- p[long_ticker]
exp_data[long_ticker,2] <- y[long_ticker]
if(exp_data[long_ticker,2]==2){
exp_data[long_ticker,2]<- 0
}
}
}
exp_overlay <- matrix(NaN,nrow = 10,ncol = 4)
exp_overlay[,1] <- seq(.035,.935,by = .1)
bin_size_exp = rep(NaN,10)
for(i in 1:nrow(exp_overlay)){
tol = .0001
lo = (i*.1)-.1
hi = i * .1
templo <- exp_data
templo[,1] <- templo[,1]+tol
temp_bin1 <- exp_data[which(templo[,1]>lo),1:2]
temphi <- temp_bin1
temphi[,1] <- temphi[,1]+tol
if(i<10){
temp_bin2 <- temp_bin1[which(temphi[,1]<hi),2]
}
else{temp_bin2 <- temp_bin1[,2]}
bin_size_exp[i] = length(temp_bin2)
exp_overlay[i,2] <- mean(temp_bin2)
nSamples = 10
nIterations = 1000
if(i==1){nSamples = 2}
bootRange <- BootstrapMean95(temp_bin2,nSamples,nIterations)
exp_overlay[i,3:4] <- bootRange
}
# Calculate inexperienced interpretation for comparison -------------------
nParticipants <- max(SONAData$Participant)
nResponses_SONA <- nParticipants * nReps
SONA_vector <- c(SONAData$EarlyResponse[which(SONAData$SpeakerEarly==1)],
SONAData$LateResponse[which(SONAData$SpeakerLate==1)])
SONA_descriptives <- matrix(NaN,nrow = 3,ncol = 1)
SONA_descriptives[1,1] <- mean(SONA_vector)
nIterations = 1000
nSamples = 100
SONA_descriptives[2:3,1] <- BootstrapMean95(SONA_vector,nSamples,nIterations)
# Alex plot for hierarchical by participant --------------------------------------------------
par(mfrow=c(1,1))
plot_index <- floor(runif(4000, min=1, max=12001))
q = seq(0,1,by = .01)
q_odds <- q/(1-q)
q_logodds <- log(q_odds)
temp_hierarchical <- q
plot(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)),frame.plot = FALSE,
axes = FALSE,xlab = '',ylab = '')
xlabels = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
xat = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
axis(side=1,pos=0,cex.axis = 1.4,lwd = 2,labels = xlabels,at = xat)
axis(side = 2, pos=0,cex.axis = 1.5,lwd = 2)
lines(x = c(0,1),y=c(0,0),lwd =2)
lines(x = c(0,1),y = c(.5,.5),lty = 4)
lines(x = c(.5,.5),y = c(0,1),lty = 4)
for(i in 2:length(alphaGrand_linking)){
temp_hierarchical <- 1/(1 + exp(-betaGrand_linking[plot_index[i]]*(q_logodds-alphaGrand_linking[plot_index[i]])))
lines(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)))
}
# plot_index <- floor(runif(4000, min=1, max=12001))
points(x=exp_overlay[,1],y=exp_overlay[,2],col = "black",pch = 16, cex = 2.2)
for(i in 1:nrow(exp_overlay)){
if(exp_overlay[i,3]-exp_overlay[i,4]!=0){
if(exp_overlay[i,3]==0){
exp_overlay[i,3] <- exp_overlay[i,3]+.005
}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "black",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('black',"black","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
nReps_nov = 12
exp_data <- matrix(NaN,nrow = (nReps*length(p)),ncol = 4)
for(i in 1:length(p)){
for(j in 1:nReps){
long_ticker = (i-1)*nReps_nov+j
exp_data[long_ticker,1] <- p[long_ticker]
exp_data[long_ticker,2] <- y[long_ticker]
if(exp_data[long_ticker,2]==2){
exp_data[long_ticker,2]<- 0
}
}
}
exp_overlay <- matrix(NaN,nrow = 10,ncol = 4)
exp_overlay[,1] <- seq(.05,.95,by = .1)
bin_size_exp = rep(NaN,10)
for(i in 1:nrow(exp_overlay)){
tol = .0001
lo = (i*.1)-.1
hi = i * .1
templo <- exp_data
templo[,1] <- templo[,1]+tol
temp_bin1 <- exp_data[which(templo[,1]>lo),1:2]
temphi <- temp_bin1
temphi[,1] <- temphi[,1]+tol
if(i<10){
temp_bin2 <- temp_bin1[which(temphi[,1]<hi),2]
}
else{temp_bin2 <- temp_bin1[,2]}
bin_size_exp[i] = length(temp_bin2)
exp_overlay[i,2] <- mean(temp_bin2)
nSamples = 10
nIterations = 1000
if(i==1){nSamples = 2}
bootRange <- BootstrapMean95(temp_bin2,nSamples,nIterations)
exp_overlay[i,3:4] <- bootRange
}
# Calculate inexperienced interpretation for comparison -------------------
nParticipants <- max(SONAData$Participant)
nResponses_SONA <- nParticipants * nReps
SONA_vector <- c(SONAData$EarlyResponse[which(SONAData$SpeakerEarly==1)],
SONAData$LateResponse[which(SONAData$SpeakerLate==1)])
SONA_descriptives <- matrix(NaN,nrow = 3,ncol = 1)
SONA_descriptives[1,1] <- mean(SONA_vector)
nIterations = 1000
nSamples = 100
SONA_descriptives[2:3,1] <- BootstrapMean95(SONA_vector,nSamples,nIterations)
# Alex plot for hierarchical by participant --------------------------------------------------
par(mfrow=c(1,1))
plot_index <- floor(runif(4000, min=1, max=12001))
q = seq(0,1,by = .01)
q_odds <- q/(1-q)
q_logodds <- log(q_odds)
temp_hierarchical <- q
plot(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)),frame.plot = FALSE,
axes = FALSE,xlab = '',ylab = '')
xlabels = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
xat = c(.1,.2,.3,.4,.5,.6,.7,.8,.9)
axis(side=1,pos=0,cex.axis = 1.4,lwd = 2,labels = xlabels,at = xat)
axis(side = 2, pos=0,cex.axis = 1.5,lwd = 2)
lines(x = c(0,1),y=c(0,0),lwd =2)
lines(x = c(0,1),y = c(.5,.5),lty = 4)
lines(x = c(.5,.5),y = c(0,1),lty = 4)
for(i in 2:length(alphaGrand_linking)){
temp_hierarchical <- 1/(1 + exp(-betaGrand_linking[plot_index[i]]*(q_logodds-alphaGrand_linking[plot_index[i]])))
lines(q,temp_hierarchical,type = 'l',col=c(rgb(0,0,0,0.002)))
}
# plot_index <- floor(runif(4000, min=1, max=12001))
points(x=exp_overlay[,1],y=exp_overlay[,2],col = "black",pch = 16, cex = 2.2)
for(i in 1:nrow(exp_overlay)){
if(exp_overlay[i,3]-exp_overlay[i,4]!=0){
if(exp_overlay[i,3]==0){
exp_overlay[i,3] <- exp_overlay[i,3]+.005
}
arrows(x0 = exp_overlay[i,1], y0 = exp_overlay[i,3],
x1 = exp_overlay[i,1], y1 = exp_overlay[i,4],code = 3,
col = "black",angle = 90, length = .1,lty = 2, lwd = 2)
}
}
points(x = SONA_descriptives[1,1],y = c(.05),pch = 18,cex = 2.2,lwd =2)
arrows(x0 = SONA_descriptives[2,1], y0 = c(.05),
x1 = SONA_descriptives[3,1], y1 = c(.05),code = 3,
lwd = 2, angle = 90, length = .1,lty=1)
legend(.005,.98,legend = c('Empirical','Inferred',"Naive Interpretation"),
pch = c(16,NA,18),lty = c(NA,1,NA),lwd = c(NA,2,2),pt.cex = c(2,NA,2),
col = c('black',"black","black"),
cex = 1.2,bty = 'n',
y.intersp = .7)
title(main=" ", line=.5, cex.main=1.8)
title(ylab="Endorsement Rate", line=1.6, cex.lab=1.8)
title(xlab="Estimated Applicability", line=1.8, cex.lab=1.8)
View(inference_table)
lo = 12000*.05
hi = 12000*.95
inference_table <- matrix(NaN, nrow = 4, ncol = 3)
inference_table[1,1] <- mean(alphaGrand_linking)
tempsort <- sort(alphaGrand_linking)
inference_table[1,2] <- tempsort[lo]
inference_table[1,3] <- tempsort[hi]
inference_table[2,1] <- mean(betaGrand_linking)
tempsort <- sort(betaGrand_linking)
inference_table[2,2] <- tempsort[lo]
inference_table[2,3] <- tempsort[hi]
inference_table[3,1] <- mean(sigmaAlpha_linking)
tempsort <- sort(sigmaAlpha_linking)
inference_table[3,2] <- tempsort[lo]
inference_table[3,3] <- tempsort[hi]
inference_table[4,1] <- mean(sigmaBeta_linking)
tempsort <- sort(sigmaBeta_linking)
inference_table[4,2] <- tempsort[lo]
inference_table[4,3] <- tempsort[hi]
mean(sigmaAlpha_linking)
View(inference_table)
save.image("~/GitHub/LoLComp/R/upload/LoLComp_study2.RData")
